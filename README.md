# Multimodal Deep Learning

## Papers
[Memory fusion network for multi-view sequential learning](https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/viewFile/17341/16122), AAAI 2018

[Tensor fusion network for multimodal sentiment analysis](https://www.aclweb.org/anthology/D17-1115.pdf), ACL 2017

[Multimodal Transformer for Unaligned Multimodal Language Sequences](https://arxiv.org/pdf/1906.00295.pdf), ACL 2019, [Github](https://github.com/yaohungt/Multimodal-Transformer)

[Adapting BERT for Target-Oriented Multimodal Sentiment Classification](https://www.ijcai.org/Proceedings/2019/0751.pdf), IJCAI 2019

[Integrating Multimodal Information in Large Pretrained Transformers](https://arxiv.org/abs/1908.05787)

[Adapting BERT for Target-Oriented Multimodal Sentiment Classification](https://www.ijcai.org/Proceedings/2019/0751.pdf)

[M-bert: Injecting multimodal information in the bert structure](https://arxiv.org/abs/1908.05787)

[Audio ALBERT: A Lite BERT for Self-supervised Learning of Audio Representation](https://arxiv.org/abs/2005.08575)

[Multimodal big data affective analytics: A comprehensive survey using text,audio, visual and physiological signals](https://www.sciencedirect.com/science/article/pii/S1084804519303078)

[Deep Multimodal Learning: A Survey on Recent Advances and Trends](https://ieeexplore.ieee.org/abstract/document/8103116)
